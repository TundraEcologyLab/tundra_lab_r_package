#' Remove Duplicate and Out-of-Bounds Data
#'
#' A function which takes a dataframe, and a name_pattern to identify columns within the
#' dataframe. For each column that matches the name_pattern, its values are converted to NA
#' if they are outwith the upper or lower limits, or if they match 6999 (an error code produced by
#' Tundra lab equipment). For every date, the data is checked to make sure any duplicate data
#' is self consistent. Any inconsistent data is written to a new file (output_dir/conflicted_data.csv)
#' before being converted to NA, except if discarding NA values would lead to consistent data.
#' All duplicated data is then removed from the dataframe before returning it.
#' @param dataframe The dataframe containing the data to be cleaned
#' @param upper_limit The limit above which data in the identified columns will be converted
#' to NA
#' @param lower_limit The limit below which data in the identified columns will be converted
#' to NA
#' @param name_pattern A string or regular expression which should match all columns,
#' and only those columns, to be cleaned
#' @param output_dir Directory to which a file of all conflicted data shall be written
#' @export

clean_data <- function(dataframe, upper_limit, lower_limit, name_pattern, output_dir){
  # Get names of all columns to clean
  names <- grep(name_pattern, names(dataframe), ignore.case = TRUE, value = TRUE)
  # create empty list for any conflicted data
  conflict_list <- list()
  # Arrange data in dataframe by ascending date
  dataframe <- arrange(dataframe, date)
  # For each column to be cleaned: convert all values outwith the given bounds, or that match
  # 6999 to NA. Calculate the standard deviation of the values that share a date in each column
  # to be cleaned. This will identify conflicted data.
  for (name in names){
    dataframe <- dataframe %>%
      dplyr::mutate("{name}" := ifelse(.data[[name]] > upper_limit |
                                  .data[[name]] < lower_limit |
                                  grepl("6999", .data[[name]]), NA, .data[[name]])) %>%
      dplyr::group_by(date) %>%
      dplyr::mutate("{name}_std" := sd(.data[[name]], na.rm = TRUE))
  }
  # Create a list of dataframes containing the data that didn't match for a given date,
  # each element of the list being a dataframe generated from analysing one column to
  # be cleaned
  for (name in names){
    conflicted_data <- dataframe %>% dplyr::filter(.data[[paste0(name, "_std")]] > 0)
    conflict_list <- append(conflict_list, list(conflicted_data))
  }
  # Combine the separate dataframes generated by each column, remove duplicates, and
  # write to file
  conflicted_data <- do.call(rbind, conflict_list)
  conflicted_data <- dplyr::distinct(conflicted_data)
  if (length(conflicted_data[[1]] > 0)){
      warning(paste0("inconsistent data has been detected, excluded, and written to ",
                  output_dir, "/conflicted_data.csv"))
  readr::write_csv(conflicted_data, paste0(output_dir, "/conflicted_data.csv"))
  }
  # For each column to be cleaned, convert any inconsistent data to NA, unless the data
  # would be consistent if NA values were removed, in which case convert the NA value to
  # match the other data from that date
  for (name in names){
   dataframe <- dataframe %>%
     dplyr::mutate("{name}" := ifelse(.data[[paste0(name, "_std")]] == 0 |
                                  is.na(.data[[paste0(name, "_std")]]), .data[[name]], NA)) %>%
      dplyr::mutate("{name}" := non_NA(.data[[name]]))

  }
  # remove duplicated data and return dataframe without the standard deviation data
  dataframe <- dataframe %>% dplyr::distinct(date, .keep_all = TRUE) %>%
  dplyr::select(!ends_with("std"))
  dataframe
}

